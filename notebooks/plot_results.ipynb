{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantify differences between models and across tasks with different parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "plt.rcParams['text.usetex'] = True\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['font.serif'] = 'Times New Roman'\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "sys.path.append('..')\n",
    "from function_vectors.src.utils import custom_utils as pqd\n",
    "from config import IMPLEMENTED_MODELS, MODEL_FP_MAP, HF_NAME_MAP, STAGE_NAME\n",
    "\n",
    "def get_baseline(model_name, data_name):\n",
    "    \"\"\"Read a JSON file and return its contents as a dictionary.\"\"\"\n",
    "    file_path = f\"../function_vectors/results/{model_name}/{data_name}/baseline_n_shots.json\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as json_file:\n",
    "            data = json.load(json_file)\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        # print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "TASKS = [\n",
    "    'antonym',\n",
    "    'english-french',\n",
    "    'english-german',\n",
    "    'english-spanish',\n",
    "    'french-english',\n",
    "    'german-english',\n",
    "    'spanish-english',\n",
    "    'present-past',\n",
    "    'country-capital'\n",
    "]\n",
    "N_TEST = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To plot across heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_subplots_data = []\n",
    "all_recovery = []\n",
    "for default_params in [True, False]:\n",
    "    all_avgs, all_peaks, all_scores, peak_layer = [], [], [], []\n",
    "    recovery = {'1': [], '5': [], '5_90': [], '5_75': [], '5_50': []}\n",
    "    for data_name in TASKS:\n",
    "        for model_name, hf_name_full in HF_NAME_MAP.items():\n",
    "            # Set configs\n",
    "            model_fp = MODEL_FP_MAP[model_name]\n",
    "            hf_name = hf_name_full.split('/')[1]\n",
    "            model_config = json.load(open(os.path.join(model_fp, 'config.json')))\n",
    "            if model_name in ['gptj-6b']:\n",
    "                n_layers = model_config['n_layer']\n",
    "            else:\n",
    "                n_layers = model_config['num_hidden_layers']\n",
    "            if float(model_name.split('-')[1][:-1]) > 27:\n",
    "                LAMBDAS = [1, 4, 16] \n",
    "                N_HEADS = [2, 64, 512, 1024]\n",
    "            else:\n",
    "                LAMBDAS = [0.5, 1, 2, 4, 8, 16, 32, 64]\n",
    "                N_HEADS = [2, 16, 32, 64, 128, 256, 512]\n",
    "            if default_params:\n",
    "                LAMBDAS = [1] \n",
    "                if float(model_name.split('-')[1][:-1]) > 27:\n",
    "                    N_HEADS = [2, 64]\n",
    "                else:\n",
    "                    N_HEADS = [2, 16]\n",
    "            # Get baseline performance\n",
    "            baseline_n_shots = get_baseline(model_name, data_name)\n",
    "            if baseline_n_shots is None:\n",
    "                continue\n",
    "            zero_shot = dict(zip([str(i) for i in range(n_layers)], [baseline_n_shots['0']] * n_layers))['0']\n",
    "            one_shot = dict(zip([str(i) for i in range(n_layers)], [baseline_n_shots['1']] * n_layers))['0']\n",
    "            five_shot = dict(zip([str(i) for i in range(n_layers)], [baseline_n_shots['5']] * n_layers))['0']\n",
    "            by_layer, avgs, peaks, scores, peak_layer = [defaultdict(list) for _ in range(5)]\n",
    "            max_perf_recovery = []\n",
    "            for col_id, n_head in enumerate(N_HEADS):\n",
    "                for row_id, lda in enumerate(LAMBDAS):\n",
    "                    n_head_clean, lda_clean = pqd.clean_numbers(n_head, lda)\n",
    "                    # Get results from Causual Indirect Effect\n",
    "                    saved_fname = f'{hf_name}_{data_name}_{n_head_clean}-top-heads_{lda_clean}-lambda_{N_TEST}-test-samples'\n",
    "                    dp = f\"../function_vectors/results/{model_name}/{data_name}/0_shot_w_FV\"\n",
    "                    results_fp = os.path.join(dp, f\"{saved_fname}.json\")\n",
    "                    if os.path.isfile(results_fp):\n",
    "                        zero_shot_fv = json.load(open(results_fp))\n",
    "                        recovery_per_layer = np.array(list(zero_shot_fv.values()))/five_shot\n",
    "                        by_layer[n_head].append(recovery_per_layer)\n",
    "                        avgs[n_head].append(np.nanmean(recovery_per_layer)) # AUC type score\n",
    "                        peaks[n_head].append(np.nanmax(recovery_per_layer)) # peak performance recovery\n",
    "                        scores[n_head].append(np.nanmean(recovery_per_layer)*np.max(recovery_per_layer)) # AUC*peak\n",
    "                        max_perf_recovery.append(np.nanmax(list(zero_shot_fv.values())))\n",
    "                # Calculate the peak layer???\n",
    "                if by_layer[n_head]:\n",
    "                    avgs[n_head] = np.max(avgs[n_head])\n",
    "                    peaks[n_head] = np.max(peaks[n_head])\n",
    "                    scores[n_head] = np.max(scores[n_head])\n",
    "                else:\n",
    "                    nan_array = np.empty(200)\n",
    "                    nan_array[:] = np.nan\n",
    "            recovery['1'].append(np.nanmax(max_perf_recovery) > zero_shot)\n",
    "            recovery['5'].append(np.nanmax(max_perf_recovery) >= five_shot)\n",
    "            recovery['5_90'].append(np.nanmax(max_perf_recovery) >= 0.90*five_shot)\n",
    "            recovery['5_75'].append(np.nanmax(max_perf_recovery) >= 0.75*five_shot)\n",
    "            recovery['5_50'].append(np.nanmax(max_perf_recovery) >= 0.50*five_shot)\n",
    "            \n",
    "            fv_df = pd.DataFrame([avgs])\n",
    "            fv_df.insert(0, 'data_name', data_name)\n",
    "            fv_df.insert(0, 'model_name', model_name)\n",
    "            all_scores.append(fv_df)\n",
    "\n",
    "            fv_df = pd.DataFrame([peaks])\n",
    "            fv_df.insert(0, 'data_name', data_name)\n",
    "            fv_df.insert(0, 'model_name', model_name)\n",
    "            all_peaks.append(fv_df)\n",
    "    all_subplots_data.append(all_scores)\n",
    "    all_subplots_data.append(all_peaks)\n",
    "    all_recovery.append(recovery)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To plot across lambdas or layers\n",
    "- (expected warnings) RuntimeWarning: All-NaN slice encountered all_layers.append(np.nanmax(np.array(list(by_layer2.values())), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_params = False\n",
    "all_subplots_data = []\n",
    "all_recovery = []\n",
    "for default_params in [True, False]:\n",
    "    all_avgs, all_peaks, all_scores, peak_layer, all_layers, model_names_l, tasks_l = [], [], [], [], [], [], []\n",
    "    n_layers_l = {}\n",
    "    recovery = {'1': [], '5': [], '5_90': [], '5_75': [], '5_50': []}\n",
    "    for model_name, hf_name_full in HF_NAME_MAP.items():\n",
    "        # Set configs\n",
    "        model_fp = MODEL_FP_MAP[model_name]\n",
    "        hf_name = hf_name_full.split('/')[1]\n",
    "        model_config = json.load(open(os.path.join(model_fp, 'config.json')))\n",
    "        if model_name in ['gptj-6b']:\n",
    "            n_layers = model_config['n_layer']\n",
    "        else:\n",
    "            n_layers = model_config['num_hidden_layers']\n",
    "        N_TEST = 50\n",
    "        if float(model_name.split('-')[1][:-1]) > 27:\n",
    "            # continue\n",
    "            LAMBDAS = [1, 4, 16] \n",
    "            N_HEADS = [2, 64, 512, 1024]\n",
    "        else:\n",
    "            LAMBDAS = [0.5, 1, 2, 4, 8, 16, 32, 64]\n",
    "            N_HEADS = [2, 16, 32, 64, 128, 256, 512]\n",
    "        if default_params:\n",
    "            LAMBDAS = [1] \n",
    "            if float(model_name.split('-')[1][:-1]) > 27:\n",
    "                N_HEADS = [2, 64]\n",
    "            else:\n",
    "                N_HEADS = [2, 16, 32]\n",
    "        n_layers_l[model_name] = n_layers\n",
    "        for data_name in TASKS:\n",
    "            # Get baseline performance\n",
    "            baseline_n_shots = get_baseline(model_name, data_name)\n",
    "            if baseline_n_shots is None:\n",
    "                continue\n",
    "            zero_shot = dict(zip([str(i) for i in range(n_layers)], [baseline_n_shots['0']] * n_layers))['0']\n",
    "            one_shot = dict(zip([str(i) for i in range(n_layers)], [baseline_n_shots['1']] * n_layers))['0']\n",
    "            five_shot = dict(zip([str(i) for i in range(n_layers)], [baseline_n_shots['5']] * n_layers))['0']\n",
    "            by_layer, by_layer2, avgs, peaks, scores, peak_layer = [defaultdict(list) for _ in range(6)]\n",
    "            max_perf_recovery = []\n",
    "            for col_id, lda in enumerate(LAMBDAS):\n",
    "                for row_id, n_head in enumerate(N_HEADS):\n",
    "                    n_head_clean, lda_clean = pqd.clean_numbers(n_head, lda)\n",
    "                    # Get results from Causual Indirect Effect\n",
    "                    saved_fname = f'{hf_name}_{data_name}_{n_head_clean}-top-heads_{lda_clean}-lambda_{N_TEST}-test-samples'\n",
    "                    dp = f\"../function_vectors/results/{model_name}/{data_name}/0_shot_w_FV\"\n",
    "                    results_fp = os.path.join(dp, f\"{saved_fname}.json\")\n",
    "                    if os.path.isfile(results_fp):\n",
    "                        zero_shot_fv = json.load(open(results_fp))\n",
    "                        recovery_per_layer = np.array(list(zero_shot_fv.values()))/five_shot\n",
    "                        by_layer[lda].append(recovery_per_layer)\n",
    "                        by_layer2[lda].append(np.array(recovery_per_layer))\n",
    "                        avgs[lda].append(np.nanmean(recovery_per_layer)) # AUC type score\n",
    "                        peaks[lda].append(np.nanmax(recovery_per_layer)) # peak performance recovery\n",
    "                        scores[lda].append(np.nanmean(recovery_per_layer)*np.max(recovery_per_layer)) # AUC*peak\n",
    "                        max_perf_recovery.append(np.nanmax(list(zero_shot_fv.values())))\n",
    "                if by_layer[lda]: # why do i do this?\n",
    "                    avgs[lda] = np.max(avgs[lda])\n",
    "                    # get peak layer if it is at least better than 1 shot\n",
    "                    use_only_gt_one_shot = np.array(by_layer[lda]) - one_shot > -0.05\n",
    "                    gt_one_shot = np.where(use_only_gt_one_shot, np.array(by_layer[lda]), -1)\n",
    "                    if gt_one_shot.sum() > -gt_one_shot.size:\n",
    "                        peak_layer[lda] = np.argmax(np.max(gt_one_shot, axis=0)) + 1\n",
    "                    else:\n",
    "                        peak_layer[lda] = np.nan#'TMP'\n",
    "                    peaks[lda] = np.max(peaks[lda])\n",
    "                    scores[lda] = np.max(scores[lda])\n",
    "                    layer_perf_lda_avg = np.array(by_layer2[lda]).max(axis=0)\n",
    "                    by_layer2[lda] = np.pad(layer_perf_lda_avg, (0, 200 - layer_perf_lda_avg.size), 'constant', constant_values=np.nan) \n",
    "                else:\n",
    "                    nan_array = np.empty(200)\n",
    "                    nan_array[:] = np.nan\n",
    "                    by_layer2[lda] =  nan_array\n",
    "            all_layers.append(np.nanmax(np.array(list(by_layer2.values())), axis=0))\n",
    "            model_names_l.append(model_name)\n",
    "            tasks_l.append(data_name)\n",
    "            recovery['1'].append(np.nanmax(max_perf_recovery) > zero_shot)\n",
    "            recovery['5'].append(np.nanmax(max_perf_recovery) >= five_shot)\n",
    "            recovery['5_90'].append(np.nanmax(max_perf_recovery) >= 0.90*five_shot)\n",
    "            recovery['5_75'].append(np.nanmax(max_perf_recovery) >= 0.75*five_shot)\n",
    "            recovery['5_50'].append(np.nanmax(max_perf_recovery) >= 0.50*five_shot)\n",
    "            \n",
    "            fv_df = pd.DataFrame([avgs])\n",
    "            fv_df.insert(0, 'data_name', data_name)\n",
    "            fv_df.insert(0, 'model_name', model_name)\n",
    "            all_scores.append(fv_df)\n",
    "\n",
    "            fv_df = pd.DataFrame([peaks])\n",
    "            fv_df.insert(0, 'data_name', data_name)\n",
    "            fv_df.insert(0, 'model_name', model_name)\n",
    "            all_peaks.append(fv_df)\n",
    "    all_subplots_data.append(all_scores)\n",
    "    all_subplots_data.append(all_peaks)\n",
    "    all_recovery.append(recovery)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run this for all plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fv_df = pd.concat(all_peaks, axis=0)\n",
    "fv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_order = [\n",
    "    'gptj-6b',       \n",
    "    'pythia-6.9b',  \n",
    "    'llama-7b',\n",
    "    'llama2-7b',   \n",
    "    'llama2i-7b',\n",
    "    'llama2-13b',    \n",
    "    'llama2i-13b',    \n",
    "    'llama2-70b',\n",
    "    'llama3-8b',\n",
    "    'llama3i-8b',\n",
    "    'llama3-70b',\n",
    "    'llama3i-70b',\n",
    "    'llama3.2-3b',    \n",
    "    'mistral1-7b',    \n",
    "    'mistral3-7b',    \n",
    "    'mistral3i-7b',\n",
    "    'amber-7b',\n",
    "    'falcon3-7b',\n",
    "    'gemma2-2b',      \n",
    "    'gemma2-9b',      \n",
    "    'gemma2i-9b',\n",
    "    'gemma2-27b',     \n",
    "    'qwen2-1.5b', \n",
    "    'qwen2-7b',      \n",
    "    'qwen2i-7b',  \n",
    "    'qwen2-72b',\n",
    "    'qwen2.5-3b',\n",
    "    'qwen2.5i-3b',\n",
    "    'qwen2.5-7b',\n",
    "    'qwen2.5i-7b',\n",
    "    'qwen2.5-14b',\n",
    "    'olmo-7b',             \n",
    "    'olmoi-7b',\n",
    "    'olmo2-7b',\n",
    "    'olmo2i-7b',\n",
    "    'olmo2-13b',\n",
    "]\n",
    "instr_order = [\n",
    "    'llama2-7b',     \n",
    "    'llama2i-7b',\n",
    "    'llama2-13b',   \n",
    "    'llama2i-13b',\n",
    "    'llama3-8b',\n",
    "    'llama3i-8b',\n",
    "    'llama3-70b',\n",
    "    'llama3i-70b',\n",
    "    'mistral3-7b',    \n",
    "    'mistral3i-7b',     \n",
    "    'gemma2-9b',      \n",
    "    'gemma2i-9b',\n",
    "    'qwen2-7b',      \n",
    "    'qwen2i-7b',  \n",
    "    'qwen2.5-3b',\n",
    "    'qwen2.5i-3b',\n",
    "    'qwen2.5-7b',\n",
    "    'qwen2.5i-7b',\n",
    "    'olmo-7b',               \n",
    "    'olmoi-7b',\n",
    "    'olmo2-7b',\n",
    "    'olmo2i-7b',\n",
    "]\n",
    "\n",
    "diff_instr = [\n",
    "    'llama2-7b',\n",
    "    'llama2-13b',\n",
    "    'llama3-8b',\n",
    "    'llama3-70b',\n",
    "    'mistral3-7b',\n",
    "    'gemma2-9b',\n",
    "    'qwen2-7b',\n",
    "    'qwen2.5-3b',\n",
    "    'qwen2.5-7b',\n",
    "    'olmo-7b',\n",
    "    'olmo2-7b',\n",
    "]\n",
    "\n",
    "instr_only = [\n",
    "    'llama2i-7b',\n",
    "    'llama2i-13b',\n",
    "    'llama3i-8b',\n",
    "    'llama3i-70b',\n",
    "    'mistral3i-7b',     \n",
    "    'gemma2i-9b',\n",
    "    'qwen2i-7b',  \n",
    "    'qwen2.5i-3b',\n",
    "    'qwen2.5i-7b',\n",
    "    'olmoi-7b',\n",
    "    'olmo2i-7b',\n",
    "]\n",
    "\n",
    "data_short_map = {\n",
    "    'antonym': 'ant',\n",
    "    'present-past': 'pres-past',\n",
    "    'country-capital': 'cntry-cap',\n",
    "    'french-english': 'fr-eng',\n",
    "    'german-english': 'ge-eng',\n",
    "    'spanish-english': 'sp-eng',\n",
    "    'english-french': 'eng-fr',\n",
    "    'english-german': 'eng-ge',\n",
    "    'english-spanish': 'eng-sp',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in Task Vector Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = False\n",
    "tv_recovery = {'0': [], '5': [], '5_90': [], '5_75': [], '5_50': []}\n",
    "all_scores, all_peaks = [], []\n",
    "for model_name in model_order:\n",
    "    model_name = model_name.replace('-', '_')\n",
    "    if os.path.exists(f'../icl_task_vectors/for_fv/{model_name}.csv'):\n",
    "        tv_fv_df = pd.read_csv(f'../icl_task_vectors/for_fv/{model_name}.csv')\n",
    "        baselines = pd.read_csv(f'../icl_task_vectors/for_fv/{model_name}_baselines.csv')\n",
    "        model_name = model_name.replace('_', '-')\n",
    "        scores, peaks = [model_name], [model_name]\n",
    "        # For performance recovery\n",
    "        for task in ['translation_fr_en', 'country-capital', 'translation_es_en', 'translation_en_fr', 'translation_en_es', 'translation_en_it', 'translation_it_en', 'present-past', 'antonym']:\n",
    "            tv_recovery['0'].append(tv_fv_df.loc[:, task].max(skipna=True, axis=0) > zero_shot)\n",
    "            tv_recovery['5'].append(tv_fv_df.loc[:, task].max(skipna=True, axis=0) >= five_shot)\n",
    "            tv_recovery['5_90'].append(tv_fv_df.loc[:, task].max(skipna=True, axis=0) >= 0.9*five_shot)\n",
    "            tv_recovery['5_75'].append(tv_fv_df.loc[:, task].max(skipna=True, axis=0) >= 0.75*five_shot)\n",
    "            tv_recovery['5_50'].append(tv_fv_df.loc[:, task].max(skipna=True, axis=0) >= 0.50*five_shot)\n",
    "            \n",
    "        for task in ['antonym', 'present-past', 'country-capital', 'to-eng', 'from-eng']:\n",
    "            zero_shot = baselines.loc[0, task]\n",
    "            five_shot = baselines.loc[1, task]\n",
    "\n",
    "            score = tv_fv_df[task].mean()*tv_fv_df[task].max()/five_shot\n",
    "            scores.append(score)\n",
    "\n",
    "            peak = tv_fv_df[task].max()/five_shot\n",
    "            peaks.append(peak)\n",
    "        all_scores.append(scores)\n",
    "        all_peaks.append(peaks)\n",
    "tv_scores = pd.DataFrame(all_scores, columns=['model_name', 'antonym', 'present-past', 'country-capital', 'to-eng', 'from-eng'])\n",
    "tv_scores.insert(1, 'for_code_consistency', 0)\n",
    "tv_peaks = pd.DataFrame(all_peaks, columns=['model_name', 'antonym', 'present-past', 'country-capital', 'to-eng', 'from-eng'])\n",
    "tv_peaks.insert(1, 'for_code_consistency', 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot heads against istr-base models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_n_models = fv_df.copy()\n",
    "\n",
    "head_n_models = head_n_models.drop(columns=['data_name']).groupby('model_name').mean()\n",
    "head_n_models = head_n_models.reindex(instr_order)\n",
    "\n",
    "even_rows = head_n_models.iloc[0::2].reset_index(drop=True)\n",
    "odd_rows = head_n_models.iloc[1::2].reset_index(drop=True)   \n",
    "head_n_models = odd_rows - even_rows\n",
    "head_n_models.index = diff_instr\n",
    "\n",
    "plt.figure(figsize=(3.5, 3))\n",
    "\n",
    "head_n_models = head_n_models.reset_index(names='model_name')\n",
    "head_n_models = pd.melt(head_n_models, id_vars='model_name', var_name='N Heads', value_name='Performance Recovery')\n",
    "ax = sns.lineplot(data=head_n_models, x='N Heads', y='Performance Recovery', linewidth=2, color='black')\n",
    "\n",
    "plt.xticks([2, 16, 32, 64, 128, 256, 512])\n",
    "plt.ylabel('Perf Recovery')\n",
    "plt.xlabel('N Heads')\n",
    "\n",
    "plt.axhline(0, color='gray', linestyle='--')\n",
    "\n",
    "ax.set_xscale('log')\n",
    "ax.set_xticks([2, 16, 32, 64, 128, 256, 512])\n",
    "ax.set_xlim([2, 512])\n",
    "ax.xaxis.set_major_formatter(ScalarFormatter())\n",
    "ax.xaxis.get_major_formatter().set_useOffset(False)\n",
    "ax.minorticks_off()\n",
    "ax.set_yticks(np.linspace(0, 0.4, 5))\n",
    "ax.tick_params('x', labelsize=12)\n",
    "ax.tick_params('y', labelsize=13)\n",
    "\n",
    "ax.set_xlabel(\"Number of Heads\", fontsize=13)\n",
    "ax.set_ylabel(\"$\\Delta$ Performance Recovery\", fontsize=13)\n",
    "\n",
    "plt.title('Post-trained Performance over Base', fontsize=13)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/activation_patching/head_instr.pdf', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot heads against task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_n_tasks = fv_df.copy()\n",
    "plt.figure(figsize=(3.5,3))\n",
    "head_n_tasks = head_n_tasks.drop(columns=['model_name'])\n",
    "head_n_tasks = pd.melt(head_n_tasks, id_vars='data_name', var_name='N Heads', value_name='Performance Recovery')\n",
    "# Formatting for plot\n",
    "head_n_tasks['data_name'] = head_n_tasks['data_name'].map(data_short_map)\n",
    "head_n_tasks['sort_order'] = head_n_tasks['data_name'].map(lambda x: list(data_short_map.values()).index(x))\n",
    "head_n_tasks = head_n_tasks.sort_values('sort_order').drop(columns=['sort_order'])\n",
    "palette = {\n",
    "    'ling and fact': '#D55E00',\n",
    "    'eng to [lang]': '#000000',\n",
    "    '[lang] to eng': '#332288',\n",
    "}\n",
    "hm2 = head_n_tasks.copy()\n",
    "hm2 = hm2.set_index('data_name')\n",
    "hm2 = hm2.rename(index={'ant': 'ling and fact', 'pres-past': 'ling and fact', 'cntry-cap': 'ling and fact'})\n",
    "hm2 = hm2.rename(index={'eng-fr': 'eng to [lang]', 'eng-ge': 'eng to [lang]', 'eng-sp': 'eng to [lang]'})\n",
    "hm2 = hm2.rename(index={'fr-eng': '[lang] to eng', 'ge-eng': '[lang] to eng', 'sp-eng': '[lang] to eng'})\n",
    "hm2 = hm2.reset_index()\n",
    "\n",
    "ax = sns.lineplot(data=hm2, x='N Heads', y='Performance Recovery', hue='data_name', style='data_name', dashes=True, linewidth=2, palette=palette)\n",
    "\n",
    "ax.set_xscale('log')\n",
    "ax.set_xticks([2, 16, 32, 64, 128, 256, 512])\n",
    "ax.set_xlim([2, 512])\n",
    "ax.xaxis.set_major_formatter(ScalarFormatter())\n",
    "ax.xaxis.get_major_formatter().set_useOffset(False)\n",
    "ax.minorticks_off()\n",
    "ax.set_yticks(np.linspace(0, 1.0, 6))\n",
    "ax.tick_params('x', labelsize=12)\n",
    "ax.tick_params('y', labelsize=13)\n",
    "\n",
    "ax.tick_params(labelsize=12)\n",
    "\n",
    "ax.set_xlabel(\"Number of Heads\", fontsize=12)\n",
    "ax.set_ylabel(\"Peak Performance Recovery\", fontsize=13)\n",
    "\n",
    "plt.legend(ncol=1, loc='lower right', bbox_to_anchor=(0.97, -0.04), fontsize=11, framealpha=0) # \n",
    "\n",
    "plt.title('Localization can be Task-Dependent', fontsize=13)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/activation_patching/head_tasks.pdf', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joint Heads analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(6, 3.5))\n",
    "\n",
    "# Left plot tasks/heads\n",
    "sns.lineplot(data=hm2, x='N Heads', y='Performance Recovery', hue='data_name', style='data_name', dashes=True, linewidth=2, palette=palette, ax=axs[0])\n",
    "axs[0].set_xscale('log')\n",
    "axs[0].set_xticks([2, 16, 32, 64, 128, 256, 512])\n",
    "axs[0].set_xlim([2, 512])\n",
    "axs[0].xaxis.set_major_formatter(ScalarFormatter())\n",
    "axs[0].xaxis.get_major_formatter().set_useOffset(False)\n",
    "axs[0].minorticks_off()\n",
    "axs[0].set_yticks(np.linspace(0, 0.9, 4))\n",
    "axs[0].tick_params('x', labelsize=15, rotation=45)\n",
    "axs[0].tick_params('y', labelsize=15)\n",
    "\n",
    "\n",
    "axs[0].set_ylabel(\"Peak Performance Recovery\", fontsize=15, y = 0.5)\n",
    "axs[0].set_xlabel('')\n",
    "\n",
    "axs[0].legend(ncol=1, loc='lower right', bbox_to_anchor=(0.99, -0.04), fontsize=12, framealpha=0) # \n",
    "\n",
    "axs[0].set_title('Task Localization', fontsize=17)\n",
    "\n",
    "# Heads and instruction tuning\n",
    "sns.lineplot(data=head_n_models, x='N Heads', y='Performance Recovery', linewidth=2, color='black', ax=axs[1])\n",
    "axs[1].set_xticks([2, 16, 32, 64, 128, 256, 512])\n",
    "axs[1].set_ylabel('Perf Recovery')\n",
    "axs[1].set_xlabel('N Heads')\n",
    "\n",
    "axs[1].axhline(0, color='gray', linestyle='--')\n",
    "\n",
    "axs[1].set_xscale('log')\n",
    "axs[1].set_xticks([2, 16, 32, 64, 128, 256, 512])\n",
    "axs[1].set_xlim([2, 512])\n",
    "axs[1].xaxis.set_major_formatter(ScalarFormatter())\n",
    "axs[1].xaxis.get_major_formatter().set_useOffset(False)\n",
    "axs[1].minorticks_off()\n",
    "axs[1].set_yticks(np.linspace(0, 0.4, 5))\n",
    "axs[1].tick_params('x', labelsize=15, rotation=45)\n",
    "axs[1].tick_params('y', labelsize=15)\n",
    "\n",
    "axs[1].set_ylabel('')\n",
    "axs[1].set_xlabel('')\n",
    "\n",
    "axs[1].set_title('Post-Trained minus Base', fontsize=17)\n",
    "\n",
    "fig.supxlabel('Number of Heads ($\\mathcal{A}_{n}$)', fontsize=15, y=0.07)\n",
    "\n",
    "\n",
    "plt.tight_layout(w_pad=0.001)\n",
    "plt.savefig('../figures/activation_patching/head_tasks_instr.pdf', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instruction performance of Task vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_n_models = tv_peaks.copy()\n",
    "\n",
    "head_n_models = head_n_models.drop(columns=['for_code_consistency'])\n",
    "head_n_models = head_n_models.set_index('model_name')\n",
    "heads_n_models = head_n_models.rename(columns=data_short_map)\n",
    "head_n_models = head_n_models.reindex(instr_order)\n",
    "\n",
    "even_rows = head_n_models.iloc[0::2].reset_index(drop=True)\n",
    "odd_rows = head_n_models.iloc[1::2].reset_index(drop=True)   \n",
    "head_n_models = odd_rows - even_rows\n",
    "head_n_models.index = diff_instr\n",
    "\n",
    "plt.figure(figsize=(4.5, 4))\n",
    "\n",
    "head_n_models = head_n_models.reset_index(names='model_name')\n",
    "head_n_models = pd.melt(head_n_models, id_vars='model_name', var_name='Task', value_name='Performance Recovery')\n",
    "ax = sns.lineplot(data=head_n_models, x='Task', y='Performance Recovery', linewidth=2, color='black')\n",
    "\n",
    "plt.axhline(0, color='gray', linestyle='--')\n",
    "\n",
    "\n",
    "ax.set_yticks(np.linspace(-0.4, 0.2, 7))\n",
    "ax.tick_params('x', labelsize=14, rotation=45)\n",
    "ax.tick_params('y', labelsize=14)\n",
    "\n",
    "ax.set_xlabel(\"ICL Task\", fontsize=15)\n",
    "ax.set_ylabel(\"$\\Delta$ Performance Recovery\", fontsize=15)\n",
    "\n",
    "plt.title('Post-Trained minus Base', fontsize=18)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/activation_patching/tv_instr.pdf', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 subplots with Performance (default/gridsearch/TV, avgs/peaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_scores = pd.concat(all_subplots_data[0], axis=0)\n",
    "d_peaks = pd.concat(all_subplots_data[1], axis=0)\n",
    "g_scores = pd.concat(all_subplots_data[2], axis=0)\n",
    "g_peaks = pd.concat(all_subplots_data[3], axis=0)\n",
    "to_plot = [d_scores, d_peaks, g_scores, g_peaks, tv_scores, tv_peaks]\n",
    "plot_titles = ['FV Default Param', 'FV Default Param', 'FV Param Search', 'FV Param Search', 'Task Vector', 'TV']\n",
    "\n",
    "fig, axs = plt.subplots(1, len(to_plot), figsize=(13.5, 21))#, dpi=300)\n",
    "\n",
    "vmin = 0\n",
    "vmax = 1.0\n",
    "norm = plt.Normalize(vmin=vmin, vmax=vmax)\n",
    "\n",
    "for i, (fv_df, title) in enumerate(zip(to_plot, plot_titles)):\n",
    "    # plot best performance across tasks and models\n",
    "    bp = fv_df.copy()\n",
    "    bp = bp.fillna(0)\n",
    "    bp['best_perf'] = bp.iloc[:, 2:].max(axis=1)\n",
    "\n",
    "    if i < 4:\n",
    "        bp = bp.pivot(index='model_name', columns='data_name', values='best_perf')#.fillna(0)\n",
    "        bp['from-eng'] = bp[['english-french', 'english-german', 'english-spanish']].mean(axis=1)\n",
    "        bp['to-eng'] = bp[['french-english', 'german-english', 'spanish-english']].mean(axis=1)\n",
    "    else:\n",
    "        bp.index = bp['model_name']\n",
    "        bp = bp.drop('model_name', axis=1)        \n",
    "\n",
    "    bp = bp.reindex(model_order)\n",
    "    bp.index = bp.index.map(STAGE_NAME)\n",
    "    if i < 2:\n",
    "        palette = sns.color_palette(\"rocket\", as_cmap=True)\n",
    "    elif i < 4:\n",
    "        palette = sns.color_palette(\"mako\", as_cmap=True)\n",
    "    else:\n",
    "        palette = sns.color_palette(\"cividis\", as_cmap=True)\n",
    "    ax = sns.heatmap(bp[['antonym', 'present-past', 'country-capital', 'to-eng', 'from-eng']], annot=False, cmap=palette, fmt='.2f', ax=axs[i], cbar=False, norm=norm)\n",
    "    ax.hlines(np.arange(0, bp.shape[0]), *ax.get_xlim(), color='black', linewidth=1.5)\n",
    "    \n",
    "    axs[i].set_ylabel('')\n",
    "    xticks = [0.5, 1.5, 2.5, 3.5, 4.5]\n",
    "    xtick_labels = ['a', 'b', 'c', 'd', 'e']\n",
    "    axs[i].set_xticks(xticks, xtick_labels)\n",
    "    axs[i].tick_params(axis='x', labelsize=45, rotation=0, length=10)\n",
    "    axs[i].set_xlabel('')\n",
    "\n",
    "    if (i+1)%2 == 0:\n",
    "        axs[i].set_title('Peak', fontsize=40)\n",
    "    else:\n",
    "        axs[i].set_title('Average', fontsize=40)\n",
    "\n",
    "    if i > 0:\n",
    "        axs[i].set_yticks([])\n",
    "    else:\n",
    "        axs[i].tick_params(axis='y', labelsize=45, rotation=0)\n",
    "\n",
    "cbar_ax1 = fig.add_axes([0.235, 0.08, 0.25, 0.02])  # [left, bottom, width, height]\n",
    "cbar_ax2 = fig.add_axes([0.568, 0.08, 0.25, 0.02])\n",
    "cbar_ax3 = fig.add_axes([0.908, 0.08, 0.25, 0.02])\n",
    "for palette_name, cbar_ax in zip(['rocket', 'mako', 'cividis'], [cbar_ax1, cbar_ax2, cbar_ax3]):\n",
    "    cbar = fig.colorbar(plt.cm.ScalarMappable(cmap=sns.color_palette(palette_name, as_cmap=True), norm=norm), cax=cbar_ax, ticks=np.linspace(0, 1.0, 3), orientation=\"horizontal\")\n",
    "    cbar.ax.tick_params(labelsize=45)\n",
    "\n",
    "fig.text(0.5275, 1.04, 'Function Vector', ha='center', fontsize=50, transform=fig.transFigure)\n",
    "fig.text(0.36, 1, 'Default Param', ha='center', fontsize=50, transform=fig.transFigure)\n",
    "fig.text(0.695, 1, 'Param Search', ha='center', fontsize=50, transform=fig.transFigure)\n",
    "fig.text(1.025, 1, 'Task Vector', ha='center', fontsize=50, transform=fig.transFigure)\n",
    "plt.tight_layout(rect=[0, 0.1, 1.2, 1])\n",
    "plt.savefig('../figures/activation_patching/6_plots_acc_all_models.pfv_df', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot best Layer, Lambda, Heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_param = r'Number of Heads ($\\mathcal{A}_{n}$)'\n",
    "# best_param = r'Function Vector Strength ($\\lambda$)'\n",
    "best_param = r'Activation Patching Layer ($\\ell$)'\n",
    "\n",
    "# plot best performance across tasks and models\n",
    "bp = fv_df.copy()\n",
    "\n",
    "if best_param[0] in ['A']:\n",
    "    layer_perf = pd.DataFrame(all_layers)\n",
    "    layer_perf.insert(0, 'model_name', model_names_l)\n",
    "    layer_perf.insert(1, 'data_name', tasks_l)\n",
    "    bp = layer_perf\n",
    "    \n",
    "    \n",
    "bp = bp.fillna(0)\n",
    "bp['best_perf'] = bp.iloc[:, 2:].max(axis=1)\n",
    "bp = bp.query(\"best_perf > 0.2\")\n",
    "\n",
    "\n",
    "argmax_map = {i: j for i, j in enumerate(bp.iloc[:, 2:].columns)}\n",
    "bp['best_perf'] = np.argmax(bp.iloc[:, 2:], axis=1)\n",
    "# bp['best_perf'] = bp['best_perf'].map(argmax_map).astype('int')\n",
    "tasks = ['antonym', 'present-past', 'country-capital', 'english-french', 'english-german', 'english-spanish', 'french-english', 'german-english', 'spanish-english']\n",
    "\n",
    "\n",
    "\n",
    "bp_raw = bp.copy()\n",
    "\n",
    "bp = bp.pivot(index='model_name', columns='data_name', values='best_perf')\n",
    "bp['from-english'] = bp[['english-french', 'english-german', 'english-spanish']].mean(axis=1)\n",
    "bp['to-english'] = bp[['french-english', 'german-english', 'spanish-english']].mean(axis=1)\n",
    "\n",
    "if best_param[0] in ['N', 'F']:\n",
    "    cmap = mcolors.ListedColormap(\n",
    "        sns.color_palette(\"mako\", n_colors=8)\n",
    "    )\n",
    "    vmin = bp.min().min()\n",
    "    vmax = bp.max().max()\n",
    "else:\n",
    "    bp = bp.div(bp.index.map(n_layers_l), axis=0) * 100\n",
    "    cmap = sns.color_palette('mako', as_cmap=True)\n",
    "    vmin = 0\n",
    "    vmax = 100\n",
    "\n",
    "bp = bp.reindex(model_order)\n",
    "bp.index = bp.index.map(STAGE_NAME)\n",
    "bp = bp[tasks]\n",
    "bp = bp.rename(columns=data_short_map)\n",
    "plt.figure(figsize=(13.5, 20))\n",
    "\n",
    "\n",
    "ax = sns.heatmap(bp, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "ax.hlines(np.arange(0, bp.shape[0]), *ax.get_xlim(), color='black', linewidth=1.5)\n",
    "\n",
    "colorbar = ax.collections[0].colorbar\n",
    "if best_param[0] in ['N', 'F']:\n",
    "    if best_param[0] == 'N':\n",
    "        category_mapping = {0: 2, 1: 16, 2: 32, 3: 64, 4: 128, 5: 256, 6: 512, 7: 1024}\n",
    "        colorbar.set_ticks(np.linspace(0.5, 6.5, 8))\n",
    "    elif best_param[0] == 'F':\n",
    "        category_mapping = {0: 0.5, 1: 1.0, 2: 2.0, 3: 4.0, 4: 8.0, 5: 16.0, 6: 32.0, 7: 64.0}\n",
    "        colorbar.set_ticks(np.linspace(0.5, 6.5, 8))\n",
    "\n",
    "    colorbar.set_ticklabels(list(category_mapping.values()), fontsize=30)\n",
    "else:\n",
    "    colorbar.set_ticks(np.linspace(0, 100, 5))  # Ensure colorbar ticks go from 0 to 1\n",
    "    colorbar.ax.tick_params(labelsize=30)\n",
    "\n",
    "# cbar = fig.colorbar(plt.cm.ScalarMappable(cmap=sns.color_palette(palette_name, as_cmap=True), norm=norm), cax=cbar_ax, ticks=np.linspace(0, 1.0, 3), orientation=\"horizontal\")\n",
    "#     cbar.ax.tick_params(labelsize=45)\n",
    "\n",
    "ax.tick_params('x', rotation=45, labelsize=40)\n",
    "ax.tick_params('y', labelsize=40)\n",
    "plt.xticks()\n",
    "plt.title(rf'Best {best_param}', fontsize=40)\n",
    "plt.xlabel('')\n",
    "plt.ylabel('')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'../figures/activation_patching/best_param/best_{best_param}.pdf', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot 5-shot vs. Peak Performance Recovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "di = {'FV Default Param': [], 'FV Param Search': [], 'Task Vector': []}\n",
    "experiments = ['FV Default Param', 'FV Param Search']\n",
    "shots = ['5', '5_90', '5_75', '5_50']\n",
    "for recovery, experiment in zip(all_recovery, experiments):\n",
    "    for shot in shots:\n",
    "        recovered = sum(recovery[shot])\n",
    "        total_n = len(recovery[shot])\n",
    "        di[experiment].append(recovered/total_n)\n",
    "        print(f'{experiment}, {shot}-shot, {recovered} out of {total_n}, {recovered/total_n}')\n",
    "    print()\n",
    "    \n",
    "shots = ['5', '5_90', '5_75', '5_50']\n",
    "for shot in shots:\n",
    "    recovered = sum(tv_recovery[shot])\n",
    "    total_n = len(tv_recovery[shot])\n",
    "    di['Task Vector'].append(recovered/total_n)\n",
    "    print(f'Task Vector, {shot}-shot, {recovered} out of {total_n}, {recovered/total_n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mr = pd.DataFrame(di)\n",
    "mr = mr.iloc[::-1, :].reset_index(drop=True)\n",
    "mr.index = [0.5, 0.75, 0.9, 1.0]\n",
    "display(mr)\n",
    "plt.figure(figsize=(3.5,3))\n",
    "ax = sns.lineplot(mr, linewidth=3)\n",
    "ax.set_xticks([0.5, 0.75, 0.9, 1.0])\n",
    "ax.set_yticks(np.linspace(0, 1, 5))\n",
    "ax.set_xlabel('Percent of 5-shot Performance')\n",
    "ax.set_ylabel('Samples Above Threshold')\n",
    "plt.legend(loc='upper right', framealpha=0)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
